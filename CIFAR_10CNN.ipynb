{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OliverDhyanchandCOW/CS200/blob/main/CIFAR_10CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omqb9NeEa8YV",
        "outputId": "5e3205fd-7020-405d-ad5a-11b23b9c0938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPooli  (None, 15, 15, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 13, 13, 32)        9248      \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 5408)              0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 64)                346176    \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 356970 (1.36 MB)\n",
            "Trainable params: 356970 (1.36 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "391/391 - 41s - loss: 1.5871 - accuracy: 0.4343 - 41s/epoch - 104ms/step\n",
            "Epoch 2/10\n",
            "391/391 - 39s - loss: 1.2393 - accuracy: 0.5626 - 39s/epoch - 100ms/step\n",
            "Epoch 3/10\n",
            "391/391 - 41s - loss: 1.1079 - accuracy: 0.6132 - 41s/epoch - 104ms/step\n",
            "Epoch 4/10\n",
            "391/391 - 41s - loss: 1.0224 - accuracy: 0.6444 - 41s/epoch - 105ms/step\n",
            "Epoch 5/10\n",
            "391/391 - 40s - loss: 0.9584 - accuracy: 0.6659 - 40s/epoch - 102ms/step\n",
            "Epoch 6/10\n",
            "391/391 - 39s - loss: 0.8985 - accuracy: 0.6876 - 39s/epoch - 101ms/step\n",
            "Epoch 7/10\n",
            "391/391 - 41s - loss: 0.8520 - accuracy: 0.7045 - 41s/epoch - 104ms/step\n",
            "Epoch 8/10\n",
            "391/391 - 39s - loss: 0.8122 - accuracy: 0.7163 - 39s/epoch - 100ms/step\n",
            "Epoch 9/10\n",
            "391/391 - 43s - loss: 0.7654 - accuracy: 0.7349 - 43s/epoch - 111ms/step\n",
            "Epoch 10/10\n",
            "391/391 - 41s - loss: 0.7321 - accuracy: 0.7453 - 41s/epoch - 106ms/step\n",
            "79/79 - 2s - loss: 0.9482 - accuracy: 0.6778 - 2s/epoch - 28ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9481813311576843, 0.6777999997138977]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#TensorFlow is an open-source machine learning library.\n",
        "import tensorflow as tf\n",
        "#Keras is a high-level api for tensorflow.\n",
        "from tensorflow import keras\n",
        "#imports the layer classes from which the neural network will be built\n",
        "from tensorflow.keras import layers\n",
        "#CIFAR-10 is a dataset containing 32x32 RGB images of 10 different classes.\n",
        "#There are 50000 training images and 10000 test images. The classes are\n",
        "#airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks.\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "#loads the images from cifar10\n",
        "(training_images, training_labels), (testing_images, testing_labels) = cifar10.load_data()\n",
        "#converts the images from float64 to float32 to improve efficiency\n",
        "#Division by 255 constrains RGB values to between 0 and 1.\n",
        "training_images = training_images.astype(\"float32\") / 255.0\n",
        "testing_images = testing_images.astype(\"float32\") / 255.0\n",
        "\n",
        "#defines the type and structure of the model\n",
        "#Sequential models map one input tensor to one output tensor and each layer can\n",
        "#completely finish its processing of the tensor without depending on information\n",
        "#from later layers.\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        #specifications for input layer\n",
        "        #The 32s represent the image dimensions.\n",
        "        #Because this is a CNN, we do not need to flatten the images.\n",
        "        #3 represents the color channels.\n",
        "        keras.Input(shape=(32, 32, 3)),\n",
        "        #specifications for convolutional layer\n",
        "        #32 represents the number of different filters/kernels.\n",
        "        #3 represents the dimensions of the kernels.\n",
        "        #Kernels can be thought of as windows or filters through which a part of\n",
        "        #the image is viewed. The indices of the kernels will be occupied by\n",
        "        #random values, and the kernel will slide or convolve across each row\n",
        "        #and column of the image, taking a dot product with the pixel values to\n",
        "        #detect features.\n",
        "        #Valid padding means the kernel will affect image dimensions.\n",
        "        #ReLU replaces negative weighted sums with zero.\n",
        "        layers.Conv2D(32, 3, padding='valid', activation='relu'),\n",
        "        #Pooling summarizes the output of the previous convolutional layer to\n",
        "        #reduce the amount of computation done.\n",
        "        #(2,2) means width and height will be halved.\n",
        "        #Max pooling means each neighborhood will be summarzed by its maximum\n",
        "        #value. For (2,2), each neighborhood is a 2x2 square.\n",
        "        layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        layers.Conv2D(32, 3, padding ='valid', activation='relu'),\n",
        "        #Flatten reshapes tensors into rank 1 tensors.\n",
        "        layers.Flatten(),\n",
        "        #Including a fully connected layer allows the network to consider all\n",
        "        #the image \"pieces\" from the convolutional layers together.\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        #The last layer has 10 nodes to map to our 10 output classes.\n",
        "        layers.Dense(10),\n",
        "    ]\n",
        ")\n",
        "\n",
        "#prints the descriptions of each layer seen before the testing results\n",
        "print(model.summary())\n",
        "\n",
        "#training configuration\n",
        "model.compile(\n",
        "    #specifications for the loss function\n",
        "    #The cross entropy function is -log(p) where p is the CNN output probability\n",
        "    #for how much it \"thinks\" the input image belongs to the correct class.\n",
        "    #The loss function is sparse because the output is represented by a single\n",
        "    #value and not a vector.\n",
        "    #from_logits uses a softmax function to convert a real number vector to a\n",
        "    #probability distribution.\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    #Adam is a gradient descent method.\n",
        "    #Learning rate determines to what degree the model is adjusted in response\n",
        "    #to the calculated error.\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=9e-4),\n",
        "    #Metrics is used to print accuracy information in the output.\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "#call to train the model\n",
        "#Verbose 2 causes training information to be printed after each epoch.\n",
        "#An epoch is an iteration through every example in the training dataset.\n",
        "#The batch size dictates how many examples are processed at once.\n",
        "model.fit(training_images, training_labels, batch_size=128, epochs=10, verbose=2)\n",
        "#call to test the model\n",
        "model.evaluate(testing_images, testing_labels, batch_size=128, verbose=2)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOY7wZRLvXX1zJFtyV4Z78E",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}