{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFIgc1Sny8raUMQmLRQdfv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OliverDhyanchandCOW/CS200/blob/main/IntermediateCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TensorFlow is an open-source machine learning library\n",
        "import tensorflow as tf\n",
        "#keras is a high-level api for tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "#cifar10 is a dataset containing 32x32 RGB images of 10 different classes,\n",
        "#there are 50000 training images and 10000 test images, the classes are\n",
        "#airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "#loads the images from cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "#converts the images from float64 to float32 to improve efficiency,\n",
        "#division constrains RGB values to between 0 and 1\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "#defines the structure of the sequential model,\n",
        "#which maps one input to one output\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        #specifications for input layer, the 32s represent the image dimensions,\n",
        "        #because this in a CNN, we do not need to flatten the images,\n",
        "        #the 3 represents the color channels\n",
        "        keras.Input(shape=(32, 32, 3)),\n",
        "        #specifications for convolutional layer\n",
        "        #32 represents the number of output color channels. 3 represents the\n",
        "        #dimensions of the kernel. Padding defaults to valid but is specified\n",
        "        #for thoroughness. Valid means the kernel will affect image dimensions.\n",
        "        #Relu is the go-to activation function\n",
        "        layers.Conv2D(32, 3, padding='valid', activation='relu'),\n",
        "        #Pooling summarizes the output of the previous convolutional layer to\n",
        "        #reduce the amount of computation done. (2,2) means width and height\n",
        "        #will be halved. Max pooling means each neighborhood will be summarzed\n",
        "        #by its maximum value. For (2,2), each neighborhood is a 2x2 square.\n",
        "        layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        layers.Conv2D(64, 3, activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        layers.Conv2D(128, 3, activation='relu'),\n",
        "        #Flatten reshapes tensors into one dimensional tensors.\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "#training configuration\n",
        "model.compile(\n",
        "    #from_logits uses a softmax function to convert a real number vector to a\n",
        "    #probability distribution.\n",
        "    #Adam is a gradient descent method. lr is the learning rate.\n",
        "    #Learning rate determines to what degree the model is adjusted in response\n",
        "    #to the calculated error.\n",
        "    #Metrics is used to print accuracy information in the output.\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=3e-4),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "#call to train the model\n",
        "#Verbose 2 causes training information to be printed after each epoch.\n",
        "#An epoch is an iteration through every example in the training dataset.\n",
        "#The batch size dictates how many examples are processed at once.\n",
        "model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)\n",
        "\n",
        "model.evaluate(x_test, y_test, batch_size=64, verbose=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omqb9NeEa8YV",
        "outputId": "293c856d-7b1d-4735-b609-1c6dbea67827"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 15, 15, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 6, 6, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                131136    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 225034 (879.04 KB)\n",
            "Trainable params: 225034 (879.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/10\n",
            "782/782 - 62s - loss: 1.5337 - accuracy: 0.4438 - 62s/epoch - 79ms/step\n",
            "Epoch 2/10\n",
            "782/782 - 60s - loss: 1.1866 - accuracy: 0.5806 - 60s/epoch - 77ms/step\n",
            "Epoch 3/10\n",
            "782/782 - 59s - loss: 1.0059 - accuracy: 0.6477 - 59s/epoch - 76ms/step\n",
            "Epoch 4/10\n",
            "782/782 - 60s - loss: 0.8918 - accuracy: 0.6895 - 60s/epoch - 77ms/step\n",
            "Epoch 5/10\n",
            "782/782 - 60s - loss: 0.8096 - accuracy: 0.7173 - 60s/epoch - 77ms/step\n",
            "Epoch 6/10\n",
            "782/782 - 59s - loss: 0.7419 - accuracy: 0.7430 - 59s/epoch - 76ms/step\n",
            "Epoch 7/10\n",
            "782/782 - 60s - loss: 0.6825 - accuracy: 0.7615 - 60s/epoch - 77ms/step\n",
            "Epoch 8/10\n",
            "782/782 - 60s - loss: 0.6358 - accuracy: 0.7783 - 60s/epoch - 77ms/step\n",
            "Epoch 9/10\n",
            "782/782 - 59s - loss: 0.5863 - accuracy: 0.7949 - 59s/epoch - 75ms/step\n",
            "Epoch 10/10\n",
            "782/782 - 60s - loss: 0.5383 - accuracy: 0.8118 - 60s/epoch - 77ms/step\n",
            "157/157 - 3s - loss: 0.8967 - accuracy: 0.7123 - 3s/epoch - 21ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8967337608337402, 0.7123000025749207]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}